{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do a project with scraping and want to focus on the analysis, I would advise you to choose one scraper. \n",
    "\n",
    "I'll be using two in this notebook because one of my objectives is to learn about webscraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium is useful for webpages that are dynamically generated or for interacting with a webpage. For example, you might want to scrape content in a card, but the default state might be set to none. As a result, you'd want a program like selenium to go in and click certain tags to make the content visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Process (for Chrome)\n",
    "To use selenium webdriver, install the selenium python package using\n",
    "\n",
    "`pip3 install selenium`\n",
    "\n",
    "Next, check the version of chrome you're using by going to the ... button in the top-right corner, \"Help\" and then \"About Chrome\".\n",
    "`chrome://settings/help`\n",
    "Based on the version, download the appropriate chromedriver from\n",
    "[ChromeDriver Downloads](https://sites.google.com/a/chromium.org/chromedriver/downloads)\n",
    "and placing it somewhere on your laptop. Then use the path as I did in the text block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "PATH = r'C:\\Program Files (x86)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, because of the scope of the project, there isn't many sites I'd need to go to and copy transcripts from. However, I know very little about webscrapers and thought this would be a good opportunity for me to try it out and use it (as well as show my progress in learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(PATH+r'\\chromedriver.exe')\n",
    "speeches_url = \"https://jamesclear.com/great-speeches\"\n",
    "\n",
    "driver.get(speeches_url)\n",
    "link_tags = driver.find_elements_by_xpath(\"//h2[text()='Famous Speeches and Great Talks']/following::ul[1]/li/a\") # //ul/li/a\n",
    "links = [tag.get_attribute('href') for tag in link_tags]\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chropath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://jamesclear.com/great-speeches/the-danger-of-a-single-story-by-chimamanda-ngozi-adichie',\n",
       " 'https://jamesclear.com/great-speeches/what-matters-more-than-your-talents-by-jeff-bezos',\n",
       " 'https://jamesclear.com/great-speeches/enough-by-john-c-bogle',\n",
       " 'https://jamesclear.com/great-speeches/the-anatomy-of-trust-by-brene-brown',\n",
       " 'https://jamesclear.com/great-speeches/creativity-in-management-by-john-cleese',\n",
       " 'https://jamesclear.com/great-speeches/solitude-and-leadership-by-william-deresiewicz',\n",
       " 'https://jamesclear.com/great-speeches/seeking-new-laws-by-richard-feynman',\n",
       " 'https://jamesclear.com/great-speeches/make-good-art-by-neil-gaiman',\n",
       " 'https://jamesclear.com/great-speeches/personal-renewal-by-john-w-gardner',\n",
       " 'https://jamesclear.com/great-speeches/your-elusive-creative-genius-by-elizabeth-gilbert']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(PATH+r'\\chromedriver.exe')\n",
    "# driver.get(links[0])\n",
    "# transcript = ''\n",
    "# title_orator = driver.find_element_by_xpath(\"//h1[@class='entry-title']\").text\n",
    "# driver.quit()\n",
    "# title_orator\n",
    "# title_orator_re = re.search('.*“(.+)”.by (.+)', ' '.join(title_orator.split(\"\\n\")))\n",
    "# title_orator_re.group(2)\n",
    "# .split(\"\\n\")\n",
    "# ''.join(title_orator.split(\"\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-50583ffee003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mscrape_speech_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'links' is not defined"
     ]
    }
   ],
   "source": [
    "def scrape_speech_data(speech_urls,save_as='',n=5):\n",
    "    i=0\n",
    "    df = pd.DataFrame(columns=['Orator','Title','Transcript','Link'])\n",
    "    num_speeches = min(len(speech_urls),n)\n",
    "    driver = webdriver.Chrome(PATH+r'\\chromedriver.exe')\n",
    "    while i < num_speeches:\n",
    "        try:\n",
    "            driver.get(speech_urls[i])\n",
    "            transcript = ''\n",
    "            title_orator = driver.find_element_by_xpath(\"//h1[@class='entry-title']\").text\n",
    "            # Not the non-standard quotation marks in my regex string\n",
    "            title_orator_re = re.search(r'“(.+)”.+by (.+)', ' '.join(title_orator.split(\"\\n\")))\n",
    "            transcript_elements = driver.find_elements_by_xpath('//h2[text() = \"Speech Transcript\"]/following-sibling::p')\n",
    "            if not transcript_elements:\n",
    "                transcript_elements = driver.find_elements_by_xpath(\"//h2[contains(text(),'Speech Transcript')]/following-sibling::div/div/div/p\")\n",
    "            for p in transcript_elements:\n",
    "                transcript += p.text + ' '\n",
    "            df.loc[i] = [title_orator_re.group(2),title_orator_re.group(1),transcript,speech_urls[i]]\n",
    "        except:\n",
    "            print(i)\n",
    "            print(\"Unexpected error:\",sys.exc_info()[0],sys.exc_info()[1])\n",
    "        i+=1\n",
    "    driver.quit()\n",
    "    if save_as:\n",
    "        df.to_excel(save_as, index=False)\n",
    "    return df\n",
    "\n",
    "scrape_speech_data(links,'',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I got the function working, my problem was getting the transcript for John C. Bogle's speech \"Enough\". Now I saw (since Selenium actually opens a window) that there's a banner that often came up for this page, but it's not actually a modal so I don't think that should be a problem. First I will take a look at the html. \n",
    "\n",
    "The html indeed has a different structure, but at least in the first 10 transcripts, it is the only page structured like that. After looking at the page for \"Enough\", I came added the next two lines:\n",
    "\n",
    "```if not transcript_elements:\n",
    "    transcript_elements = driver.find_elements_by_xpath(\"//h2[contains(text(),'Speech Transcript')]/following-sibling::div/div/div/p\")\n",
    "```\n",
    "\n",
    "Which uses this alternate x_path in the case that the usual ```transcript_elements``` list is empty. Although sort of hacky, it works and without giving me an error. We now have our complete speech dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beautifulsoup4 is normally preferred for static sites (like the ones I'm using) or if there's a lot of pages to scrape. bs4 is faster and more robust than Selenium so it's usually preferred if possible.  \n",
    "\n",
    "Before running the code, make sure you insalled the necessary packages:\n",
    "\n",
    "`pip3 install beautifulsoup4`\n",
    "\n",
    "`pip3 install requests` (for http requests)\n",
    "\n",
    "`pip3 install lxml` (for parsing)\n",
    "\n",
    "If you have the time, I would recommend trying out both of these popular options because they are quite different and scraping $\\textit{can}$ be fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using bs4 for scraping lyrics from https://www.azlyrics.com/ which seems to have songs and albums besides \"Greatest Hits\" albums which we'll be avoiding. Using a Business Insider article from 2016, we'll collect lyrics from songs from the best selling albums of all time. \n",
    "\n",
    "Best selling is a quantifiable selection criteria, so I'll go with this methodology for songs. I'm selecting albums instead of individual songs because song popularity is very subjective (hard to find an objective list) and albums will have corpora that are more comparable to speeches than songs. Plus songs normally focus on one topic whereas speeches often have stories or subtopics that give them more variety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we want to check if the pages we are scraping allow it. https://www.businessinsider.com/robots.txt tells us, that for `User-agent: *` (ie. all bots), we cannot scrape a whole bunch of extensions. They don't disallow '/' so since my artice below is just \"businessinsider.com/...\" then I'm ok to scrape it.\n",
    "\n",
    "For how to interpret a robots.txt file, go to the [Google Webmasters](https://support.google.com/webmasters/answer/6062596?hl=en) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from time import sleep\n",
    "\n",
    "agent = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'}\n",
    "best_albums_src = requests.get('https://www.businessinsider.com/50-best-selling-albums-all-time-2016-9',headers=agent).text\n",
    "# class 'slide'\n",
    "soup = BeautifulSoup(best_albums_src, 'lxml')\n",
    "\n",
    "# show (still not that) pretty html\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slides = soup.find('div',class_='slide-wrapper')\n",
    "slide_ls = slides.find_all('div',class_='slide')\n",
    "len(slide_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so looks like we have out 50 best-selling albums. Next, we'll want the 5 best selling albums and artists without \"Greatest\" in the album title (since azlyrics doesn't have those albums and it's a good site to scrape). Possible alternatives like Lyrics.com are harder to navigate en masse (page urls can't be guessed since they have long numbers) and they don't have straightforward album-song navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Michael Jackson', '\"Thriller\"'],\n",
       " ['Eagles', '\"Hotel California\"'],\n",
       " ['Led Zeppelin', '\"Led Zeppelin IV\"'],\n",
       " ['Pink Floyd', '\"The Wall\"'],\n",
       " ['AC/DC', '\"Back In Black\"'],\n",
       " ['Garth Brooks', '\"Double Live\"'],\n",
       " ['Hootie & The Blowfish', '\"Cracked Rear View\"'],\n",
       " ['Fleetwood Mac', '\"Rumours\"'],\n",
       " ['Shania Twain', '\"Come On Over\"'],\n",
       " ['The Beatles', '\"The Beatles\" (\"The White Album\"']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_albums = 10\n",
    "\n",
    "def get_valid_albums(slides, n):\n",
    "    i=len(slides)-1\n",
    "    selected_albums = 0\n",
    "    album_info = []\n",
    "    while i > -1 and selected_albums < n:\n",
    "        txt = slides[i].text\n",
    "        if \"Greatest\" not in txt:\n",
    "            artist_album_str = re.search(r'.*\\d\\. (.+) — (\".+\").*', txt)\n",
    "            album_info.append([artist_album_str.group(1),artist_album_str.group(2)])\n",
    "            selected_albums+=1\n",
    "        i-=1\n",
    "    return album_info\n",
    "\n",
    "# Note that album names are in quotes on AZlyrics so we'll keep them in the string\n",
    "art_alb_pairs = get_valid_albums(slide_ls, num_albums)\n",
    "art_alb_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at azlyrics, the album name doesn't have quotes in the same spots\n",
    "#   (Also I didn't account for parentheses)\n",
    "art_alb_pairs[-1] =  ['The Beatles', '\"The Beatles (The White Album)\"']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have our artist and albums. The URL with album and song lyrics is pretty straightforward. URLs follow the pattern\n",
    "`https://www.azlyrics.com/<first letter of artist's last name>/<last name>.html` or \n",
    "`https://www.azlyrics.com/<first letter of group name>/<group name (only letters)>.html`\n",
    "\n",
    "Our problem is that we can't really tell if the name is a group or an individual (and I'm not about to train a model to distinguish the two). I'll be using the fact that names are (usually) two words and that we would be redirected to the main page if the url isn't found to bypass this problem. Artists with three names (so far as I've seen) have URLs like groups. There's also some inconsistency with the two word names since Billy Joel is at `/b/billyjoel.html` and Michael Jackson is at `/j/jackson.html`. I thought maybe since the Jackson 5 was linked on the same page that this was the reason for a different pattern, but David bowie is also at `/b/bowie.html`. I won't agonize it too much, I will just see if I can get success on one of the possible pages.\n",
    "\n",
    "The home page has \"Welcome to AZLyrics!\" so I'll be looking for that as a sign that my URL didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.azlyrics.com/f/fleetwood.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/secondhandnews.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/dreams.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/nevergoingbackagain.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/dontstop.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/goyourownway.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/songbird.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/thechain.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/youmakelovingfun.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/idontwanttoknow.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/ohdaddy.html',\n",
       "  'https://www.azlyrics.com/f/fleetwood.html/../../lyrics/fleetwoodmac/golddustwoman.html'],\n",
       " 'https://www.azlyrics.com/f/fleetwood.html')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az_root = 'https://www.azlyrics.com'\n",
    "\n",
    "def get_songs(artist,album, root_url=az_root):\n",
    "    h1 = None\n",
    "    songs=[]\n",
    "    artist_lc = artist.lower()\n",
    "    name = artist_lc.split()\n",
    "    artist_letters = re.sub('[^a-zA-Z]+', '', artist_lc)\n",
    "    # try last name centric URL\n",
    "    # ex. Michael Jackson -> /j/jackson.html\n",
    "    if len(name) == 2:\n",
    "        artist_url = '/'.join([root_url,name[1][0],name[1]])+'.html'\n",
    "        src = requests.get(artist_url,headers=agent).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        h1 = soup.find('h1')\n",
    "    # try full artist name url\n",
    "    # ex. AC/DC -> /a/acdc.html\n",
    "    if h1 is not None and h1.text == \"Welcome to AZLyrics!\":\n",
    "        artist_url = '/'.join([root_url,artist[0],artist_letters])+'.html'\n",
    "        src = requests.get(artist_url.lower(),headers=agent).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        h1 = soup.find('h1')\n",
    "    # try first word centric URL\n",
    "    # ex. Fleetwood Mac -> /f/fleetwood.html\n",
    "    if h1 is not None and h1.text == \"Welcome to AZLyrics!\":\n",
    "        artist_url = '/'.join([root_url,name[0][0],name[0]])+'.html'\n",
    "        src = requests.get(artist_url.lower(),headers=agent).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "    print(artist_url)\n",
    "    try:\n",
    "        # every other sibling is a navigablestring (and don't want to add more complexity to the loop)\n",
    "        cur_node = soup.findAll('b',string=album)[0].parent.next_sibling.next_sibling\n",
    "        while \"listalbum-item\" in  cur_node['class']:\n",
    "            songs.append(artist_url + '/../' + cur_node.find('a')['href'])\n",
    "            cur_node = cur_node.next_sibling.next_sibling\n",
    "    except:\n",
    "        print(sys.exc_info()[0],sys.exc_info()[1])\n",
    "    return songs, artist_url\n",
    "\n",
    "get_songs(art_alb_pairs[7][0],art_alb_pairs[7][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Well... maybe we're halfway there, but that's still something!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.azlyrics.com/j/jackson.html\n",
      "\n",
      "\n",
      "I said you wanna \n",
      "\n",
      "\n",
      "I don't need no d\n",
      "\n",
      "\n",
      "[Michael:]\n",
      "Every n\n",
      "\n",
      "\n",
      "[Michael Jackson:]\n",
      "\n",
      "\n",
      "They told him, \"D\n",
      "\n",
      "\n",
      "She was more like\n",
      "\n",
      "\n",
      "Looking out\n",
      "Acros\n",
      "\n",
      "\n",
      "You know, youây\n",
      "\n",
      "\n",
      "There'll be no da\n",
      "\n",
      "\n",
      "She's from a worl\n",
      "Unexpected error: <class 'UnboundLocalError'> local variable 'artist_url' referenced before assignment\n",
      "https://www.azlyrics.com/L/ledzeppelin.html\n",
      "\n",
      "\n",
      "Hey, hey mama, sa\n",
      "\n",
      "\n",
      "It's been a long \n",
      "\n",
      "\n",
      "The Queen of Ligh\n",
      "\n",
      "\n",
      "There's a lady wh\n",
      "\n",
      "\n",
      "Walkin' in the pa\n",
      "\n",
      "\n",
      "One, two, three, \n",
      "\n",
      "\n",
      "Spent my days wit\n",
      "\n",
      "\n",
      "If it keeps on ra\n",
      "https://www.azlyrics.com/P/pinkfloyd.html\n",
      "\n",
      "\n",
      "(We came in)\n",
      "\n",
      "So \n",
      "\n",
      "\n",
      "Momma loves her b\n",
      "\n",
      "\n",
      "Daddy's flown acr\n",
      "\n",
      "\n",
      "You! Yes, you! St\n",
      "\n",
      "\n",
      "We don't need no \n",
      "\n",
      "\n",
      "Mother, do you th\n",
      "\n",
      "\n",
      "[A child's voice:]\n",
      "\n",
      "\n",
      "[backwards message\n",
      "\n",
      "\n",
      "I am just a new b\n",
      "\n",
      "\n",
      "\"Oh my God! What \n",
      "\n",
      "\n",
      "Ooh babe\n",
      "Don't le\n",
      "\n",
      "\n",
      "I don't need no a\n",
      "\n",
      "\n",
      "Goodbye cruel wor\n",
      "\n",
      "\n",
      "Hey, you!\n",
      "Out the\n",
      "\n",
      "\n",
      "Is there anybody \n",
      "\n",
      "\n",
      "I've got a little\n",
      "\n",
      "\n",
      "Does anybody here\n",
      "\n",
      "\n",
      "Bring the boys ba\n",
      "\n",
      "\n",
      "Hello\n",
      "Is there an\n",
      "\n",
      "\n",
      "Ooh Ma Ooh Pa\n",
      "Mus\n",
      "\n",
      "\n",
      "So ya thought ya \n",
      "\n",
      "\n",
      "Run, run, run, ru\n",
      "\n",
      "\n",
      "Eins, zwei, drei,\n",
      "\n",
      "\n",
      "Stop\n",
      "I wanna go \n",
      "\n",
      "\n",
      "[Prosecutor:]\n",
      "Good\n",
      "\n",
      "\n",
      "All alone or in t\n",
      "Unexpected error: <class 'UnboundLocalError'> local variable 'artist_url' referenced before assignment\n",
      "https://www.azlyrics.com/b/brooks.html\n",
      "\n",
      "\n",
      "We all came here \n",
      "\n",
      "\n",
      "Johnny grew up\n",
      "O\n",
      "\n",
      "\n",
      "[written by Benita\n",
      "Unexpected error: <class 'UnboundLocalError'> local variable 'artist_url' referenced before assignment\n",
      "https://www.azlyrics.com/F/fleetwoodmac.html\n",
      "<class 'IndexError'> list index out of range\n",
      "https://www.azlyrics.com/t/twain.html\n",
      "\n",
      "\n",
      "Let's go girls! C\n",
      "\n",
      "\n",
      "I don't need a sh\n",
      "\n",
      "\n",
      "Life was goin' gr\n",
      "\n",
      "\n",
      "You're so complic\n",
      "\n",
      "\n",
      "I do swear that I\n",
      "\n",
      "\n",
      "Get a life-get a \n",
      "\n",
      "\n",
      "If elephants coul\n",
      "\n",
      "\n",
      "Deep in Denialvil\n",
      "\n",
      "\n",
      "Let me let you in\n",
      "\n",
      "\n",
      "(When I first saw\n",
      "\n",
      "\n",
      "The car won't sta\n",
      "\n",
      "\n",
      "I've known a few \n",
      "\n",
      "\n",
      "Black eyes, I don\n",
      "\n",
      "\n",
      "Together-midnight\n",
      "\n",
      "\n",
      "I woke up this mo\n",
      "\n",
      "\n",
      "You've got a way \n",
      "https://www.azlyrics.com/b/beatles.html\n",
      "<class 'IndexError'> list index out of range\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>\"Thriller\"</td>\n",
       "      <td>\\n\\r\\nI said you wanna be startin' somethin'\\n...</td>\n",
       "      <td>https://www.azlyrics.com/j/jackson.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>\"Hotel California\"</td>\n",
       "      <td>\\n\\r\\nI said you wanna be startin' somethin'\\n...</td>\n",
       "      <td>https://www.azlyrics.com/j/jackson.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Led Zeppelin</td>\n",
       "      <td>\"Led Zeppelin IV\"</td>\n",
       "      <td>\\n\\r\\nHey, hey mama, said the way you move\\nGo...</td>\n",
       "      <td>https://www.azlyrics.com/l/ledzeppelin.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pink Floyd</td>\n",
       "      <td>\"The Wall\"</td>\n",
       "      <td>\\n\\r\\n(We came in)\\n\\nSo ya thought ya might l...</td>\n",
       "      <td>https://www.azlyrics.com/p/pinkfloyd.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC/DC</td>\n",
       "      <td>\"Back In Black\"</td>\n",
       "      <td>\\n\\r\\n(We came in)\\n\\nSo ya thought ya might l...</td>\n",
       "      <td>https://www.azlyrics.com/p/pinkfloyd.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Garth Brooks</td>\n",
       "      <td>\"Double Live\"</td>\n",
       "      <td>\\n\\r\\nWe all came here for a party tonight\\nAn...</td>\n",
       "      <td>https://www.azlyrics.com/b/brooks.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hootie &amp; The Blowfish</td>\n",
       "      <td>\"Cracked Rear View\"</td>\n",
       "      <td>\\n\\r\\nWe all came here for a party tonight\\nAn...</td>\n",
       "      <td>https://www.azlyrics.com/b/brooks.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fleetwood Mac</td>\n",
       "      <td>\"Rumours\"</td>\n",
       "      <td></td>\n",
       "      <td>https://www.azlyrics.com/f/fleetwoodmac.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shania Twain</td>\n",
       "      <td>\"Come On Over\"</td>\n",
       "      <td>\\n\\r\\nLet's go girls! Come on.\\n\\nI'm going ou...</td>\n",
       "      <td>https://www.azlyrics.com/t/twain.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Beatles</td>\n",
       "      <td>\"The Beatles\" (\"The White Album\"</td>\n",
       "      <td></td>\n",
       "      <td>https://www.azlyrics.com/b/beatles.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Artist                             Album  \\\n",
       "0        Michael Jackson                        \"Thriller\"   \n",
       "1                 Eagles                \"Hotel California\"   \n",
       "2           Led Zeppelin                 \"Led Zeppelin IV\"   \n",
       "3             Pink Floyd                        \"The Wall\"   \n",
       "4                  AC/DC                   \"Back In Black\"   \n",
       "5           Garth Brooks                     \"Double Live\"   \n",
       "6  Hootie & The Blowfish               \"Cracked Rear View\"   \n",
       "7          Fleetwood Mac                         \"Rumours\"   \n",
       "8           Shania Twain                    \"Come On Over\"   \n",
       "9            The Beatles  \"The Beatles\" (\"The White Album\"   \n",
       "\n",
       "                                               Lyric  \\\n",
       "0  \\n\\r\\nI said you wanna be startin' somethin'\\n...   \n",
       "1  \\n\\r\\nI said you wanna be startin' somethin'\\n...   \n",
       "2  \\n\\r\\nHey, hey mama, said the way you move\\nGo...   \n",
       "3  \\n\\r\\n(We came in)\\n\\nSo ya thought ya might l...   \n",
       "4  \\n\\r\\n(We came in)\\n\\nSo ya thought ya might l...   \n",
       "5  \\n\\r\\nWe all came here for a party tonight\\nAn...   \n",
       "6  \\n\\r\\nWe all came here for a party tonight\\nAn...   \n",
       "7                                                      \n",
       "8  \\n\\r\\nLet's go girls! Come on.\\n\\nI'm going ou...   \n",
       "9                                                      \n",
       "\n",
       "                                    Artist_Link  \n",
       "0       https://www.azlyrics.com/j/jackson.html  \n",
       "1       https://www.azlyrics.com/j/jackson.html  \n",
       "2   https://www.azlyrics.com/l/ledzeppelin.html  \n",
       "3     https://www.azlyrics.com/p/pinkfloyd.html  \n",
       "4     https://www.azlyrics.com/p/pinkfloyd.html  \n",
       "5        https://www.azlyrics.com/b/brooks.html  \n",
       "6        https://www.azlyrics.com/b/brooks.html  \n",
       "7  https://www.azlyrics.com/f/fleetwoodmac.html  \n",
       "8         https://www.azlyrics.com/t/twain.html  \n",
       "9       https://www.azlyrics.com/b/beatles.html  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_speech_data(aa_list,save_as='',n=10):\n",
    "    i=0\n",
    "    df = pd.DataFrame(columns=['Artist','Album','Lyric','Artist_Link'])\n",
    "    num_albums = min(len(aa_list),n)\n",
    "    for aa in aa_list:\n",
    "        try:\n",
    "            song_links,artist_url = get_songs(aa[0],aa[1])\n",
    "            lyrics = ''\n",
    "            for song in song_links:\n",
    "                song_src = requests.get(song,headers=agent).text\n",
    "                soup = BeautifulSoup(song_src, 'lxml')\n",
    "                node = soup.find('div',class_='ringtone').next_sibling\n",
    "                while True:\n",
    "                    if type(node) is not NavigableString and node.name == 'div' and not node.attrs.get(\"class\"):\n",
    "                        lyrics += node.text + ' '\n",
    "                        break\n",
    "                    node = node.next_sibling\n",
    "                # Suspend the thread - don't hit the site too fast\n",
    "                sleep(15)\n",
    "        except:\n",
    "            print(\"Unexpected error:\",sys.exc_info()[0],sys.exc_info()[1])\n",
    "        df.loc[i] = [aa[0],aa[1],lyrics,artist_url.lower()]\n",
    "        i+=1\n",
    "    if save_as:\n",
    "        df.to_excel(save_as, index=False)\n",
    "    return df\n",
    "\n",
    "scrape_speech_data(art_alb_pairs,'songs_raw.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
