{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do a project with scraping and want to focus on the analysis, I would advise you to choose one scraper. \n",
    "\n",
    "I'll be using two in this notebook because one of my objectives is to learn about webscraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium is useful for webpages that are dynamically generated or for interacting with a webpage. For example, you might want to scrape content in a card, but the default state might be set to none. As a result, you'd want a program like selenium to go in and click certain tags to make the content visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Process (for Chrome)\n",
    "To use selenium webdriver, install the selenium python package using\n",
    "\n",
    "`pip3 install selenium`\n",
    "\n",
    "Next, check the version of chrome you're using by going to the ... button in the top-right corner, \"Help\" and then \"About Chrome\".\n",
    "`chrome://settings/help`\n",
    "Based on the version, download the appropriate chromedriver from\n",
    "[ChromeDriver Downloads](https://sites.google.com/a/chromium.org/chromedriver/downloads)\n",
    "and placing it somewhere on your laptop. Then use the path as I did in the text block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "PATH = r'C:\\Program Files (x86)'\n",
    "driver = webdriver.Chrome(PATH+r'\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, because of the scope of the project, there isn't many sites I'd need to go to and copy transcripts from. However, I know very little about webscrapers and thought this would be a good opportunity for me to try it out and use it (as well as show my progress in learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_url = \"https://jamesclear.com/great-speeches\"\n",
    "\n",
    "driver.get(speeches_url)\n",
    "link_tags = driver.find_elements_by_xpath(\"//h2[text()='Famous Speeches and Great Talks']/following::ul[1]/li/a\") # //ul/li/a\n",
    "links = [tag.get_attribute('href') for tag in link_tags]\n",
    "\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chropath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://jamesclear.com/great-speeches/the-danger-of-a-single-story-by-chimamanda-ngozi-adichie',\n",
       " 'https://jamesclear.com/great-speeches/what-matters-more-than-your-talents-by-jeff-bezos',\n",
       " 'https://jamesclear.com/great-speeches/enough-by-john-c-bogle',\n",
       " 'https://jamesclear.com/great-speeches/the-anatomy-of-trust-by-brene-brown',\n",
       " 'https://jamesclear.com/great-speeches/creativity-in-management-by-john-cleese',\n",
       " 'https://jamesclear.com/great-speeches/solitude-and-leadership-by-william-deresiewicz',\n",
       " 'https://jamesclear.com/great-speeches/seeking-new-laws-by-richard-feynman',\n",
       " 'https://jamesclear.com/great-speeches/make-good-art-by-neil-gaiman',\n",
       " 'https://jamesclear.com/great-speeches/personal-renewal-by-john-w-gardner',\n",
       " 'https://jamesclear.com/great-speeches/your-elusive-creative-genius-by-elizabeth-gilbert']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for link in links[:5]:\n",
    "    speeches_url = \"https://jamesclear.com/great-speeches\"\n",
    "    driver.get(speeches_url)\n",
    "\n",
    "    link_tags = driver.find_elements_by_xpath('//div[@class=\"entry content\"]/h2[. = \"Speech Transcript\"]/following-sibling::p')\n",
    "        #\"//*[preceding-sibling::h2[. = 'Speech Transcript'] and following-sibling::h2[. = 'Headline 2']]\")\n",
    "driver.quit()\n",
    "link_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beautifulsoup4 is normally preferred for static sites (like the ones I'm using) or if there's a lot of pages to scrape. bs4 is faster and more robust than Selenium so it's usually preferred if possible.  \n",
    "\n",
    "Before running the code, make sure you insalled the necessary packages:\n",
    "\n",
    "`pip3 install beautifulsoup4`\n",
    "\n",
    "`pip3 install requests` (for http requests)\n",
    "\n",
    "`pip3 install lxml` (for parsing)\n",
    "\n",
    "If you have the time, I would recommend trying out both of these popular options because they are quite different and scraping $\\textit{can}$ be fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using bs4 for scraping lyrics from https://www.azlyrics.com/ which seems to have songs and albums besides \"Greatest Hits\" albums which we'll be avoiding. Using a Business Insider article from 2016, we'll collect lyrics from songs from the best selling albums of all time. \n",
    "\n",
    "Best selling is a quantifiable selection criteria, so I'll go with this methodology for songs. I'm selecting albums instead of individual songs because song popularity is very subjective (hard to find an objective list) and albums will have corpora that are more comparable to speeches than songs. Plus songs normally focus on one topic whereas speeches often have stories or subtopics that give them more variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Again, we want to check if the pages we are scraping allow it. https://www.businessinsider.com/robots.txt tells us, that for `User-agent: *` (ie. all bots), we cannot scrape a whole bunch of extensions. They don't disallow '/' so since my artice below is just \"businessinsider.com/...\" then I'm ok to scrape it.\n",
    "\n",
    "For how to interpret a robots.txt file, go to the [Google Webmasters](https://support.google.com/webmasters/answer/6062596?hl=en) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "# import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "best_albums_src = requests.get('https://www.businessinsider.com/50-best-selling-albums-all-time-2016-9').text\n",
    "# class 'slide'\n",
    "soup = BeautifulSoup(best_albums_src, 'lxml')\n",
    "# show (still not that) pretty html\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides = soup.find('div',class_='slide-wrapper')\n",
    "slide_ls = slides.find_all('div',class_='slide')\n",
    "len(slide_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so looks like we have out 50 best-selling albums. Next, we'll want the 5 best selling albums and artists without \"Greatest\" in the album title (since azlyrics doesn't have those albums and it's a good site to scrape). Possible alternatives like Lyrics.com are harder to navigate en masse (page urls can't be guessed since they have long numbers) and they don't have straightforward album-song navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_albums = 5\n",
    "\n",
    "def get_valid_albums(slides, n):\n",
    "    i=len(slides)-1\n",
    "    selected_albums = 0\n",
    "    album_info = []\n",
    "    while i > -1 and selected_albums < n:\n",
    "        txt = slides[i].text\n",
    "        if \"Greatest\" not in txt:\n",
    "            artist_album_str = re.search(r'.*\\d\\. (.+) â€” (\".+\").*', txt)\n",
    "            album_info.append([artist_album_str.group(1),artist_album_str.group(2)])\n",
    "            selected_albums+=1\n",
    "        i-=1\n",
    "    return album_info\n",
    "\n",
    "get_valid_albums(slide_ls, num_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have our artist and albums. The URL with album and song lyrics is pretty straightforward. URLs follow the pattern\n",
    "`https://www.azlyrics.com/<first letter of artist's last name>/<last name>.html` or \n",
    "`https://www.azlyrics.com/<first letter of group name>/<group name (only letters)>.html`\n",
    "\n",
    "Our problem is that we can't really tell if the name is a group or an individual (and I'm not about to train a model to distinguish the two). I'll be using the fact that names are (usually) two words and that we would be redirected to the main page if the url isn't found to bypass this problem. Artists with three names (so far as I've seen) have URLs like groups. There's also some inconsistency with the two word names since Billy Joel is at `/b/billyjoel.html` and Michael Jackson is at `/j/jackson.html`. I thought maybe since the Jackson 5 was linked on the same page that this was the reason for a different pattern, but David bowie is also at `/b/bowie.html`. I won't agonize it too much, I will just see if I can get success on one of the possible pages.\n",
    "\n",
    "The home page has \"Welcome to AZLyrics!\" so I'll be looking for that as a sign that my URL didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_root = 'https://www.azlyrics.com/'\n",
    "\n",
    "def get_songs(artist,album, root_url=az_root):\n",
    "    name = artist.split()\n",
    "    if len(name) == 2:\n",
    "        # try last name centric URL\n",
    "        requests.get('/'.join(root_url,name[1][0],name[1])\n",
    "#                      ['href']\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
