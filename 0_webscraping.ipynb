{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello and welcome to my project! In this section, we'll be going over the process for data collection using popular Python web scrapers, Selenium and BeautifulSoup4 (aka bs4). This is my first time using scrapers of any kind, but in learning I've left comments on what I learned about best practices and the installation process.\n",
    "\n",
    "The reason why I'm using Selenium and bs4 is because one of my objectives for this project is to learn about webscraping. For more on the project/motivation, take a look at the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should I use BeautifulSoup4 or Selenium?\n",
    "Selenium is generally used for webpages that have dynamic components or for interacting with a webpage (sometimes done for QA). For example, you might want to scrape the content in a card, but the default state might be set to none. As a result, you'd want a tool like selenium to go in and click certain elements to make the content accessible.\n",
    "\n",
    "bs4 is normally preferred for static sites (like the ones I'm using) or if there's a lot of pages to scrape. bs4 is faster (since it doesn't need to fetch as many components) and more robust than Selenium, so it's usually preferred. \n",
    "\n",
    "[Source](https://stackoverflow.com/questions/17436014/selenium-versus-beautifulsoup-for-web-scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Process (for Chrome)\n",
    "To use selenium webdriver, install the selenium python package using\n",
    "\n",
    "`pip install selenium`\n",
    "\n",
    "Next, check the version of chrome you're using by going to the ... button in the top-right corner, \"Help\" and then \"About Chrome\".\n",
    "`chrome://settings/help`\n",
    "Based on the version, download the appropriate chromedriver from\n",
    "[ChromeDriver Downloads](https://sites.google.com/a/chromium.org/chromedriver/downloads)\n",
    "and placing it somewhere on your laptop. Then use the path as I did in the text block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "PATH = r'C:\\Program Files (x86)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, because of the scope of the project, there aren't many sites I need to go to to copy transcripts. However, I know very little about webscrapers and thought this would be a good opportunity for me to try it out and use it (as well as show my progress in learning).\n",
    "\n",
    "$\\textbf{Note about xpath: }$\n",
    "I used the Google extention Chropath to help me understand/get the xpaths needed for this portion of the project. Note it has permission to read the sites you go on, so if you don't want that, change the settings so that it only reads when you click on the extension icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(PATH+r'\\chromedriver.exe')\n",
    "speeches_url = \"https://jamesclear.com/great-speeches\"\n",
    "\n",
    "driver.get(speeches_url)\n",
    "link_tags = driver.find_elements_by_xpath(\"//h2[text()='Famous Speeches and Great Talks']/following::ul[1]/li/a\")\n",
    "links = [tag.get_attribute('href') for tag in link_tags]\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://jamesclear.com/great-speeches/the-danger-of-a-single-story-by-chimamanda-ngozi-adichie',\n",
       " 'https://jamesclear.com/great-speeches/what-matters-more-than-your-talents-by-jeff-bezos',\n",
       " 'https://jamesclear.com/great-speeches/enough-by-john-c-bogle',\n",
       " 'https://jamesclear.com/great-speeches/the-anatomy-of-trust-by-brene-brown',\n",
       " 'https://jamesclear.com/great-speeches/creativity-in-management-by-john-cleese',\n",
       " 'https://jamesclear.com/great-speeches/solitude-and-leadership-by-william-deresiewicz',\n",
       " 'https://jamesclear.com/great-speeches/seeking-new-laws-by-richard-feynman',\n",
       " 'https://jamesclear.com/great-speeches/make-good-art-by-neil-gaiman',\n",
       " 'https://jamesclear.com/great-speeches/personal-renewal-by-john-w-gardner',\n",
       " 'https://jamesclear.com/great-speeches/your-elusive-creative-genius-by-elizabeth-gilbert']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 10 urls\n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orator</th>\n",
       "      <th>Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chimamanda Ngozi Adichie</td>\n",
       "      <td>The Danger of a Single Story</td>\n",
       "      <td>I'm a storyteller. And I would like to tell yo...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/the-dang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>What Matters More Than Your Talents</td>\n",
       "      <td>As a kid, I spent my summers with my grandpare...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/what-mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John C. Bogle</td>\n",
       "      <td>Enough</td>\n",
       "      <td>Here’s how I recall the wonderful story that s...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/enough-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brené Brown</td>\n",
       "      <td>The Anatomy of Trust</td>\n",
       "      <td>Oh, it just feels like an incredible understat...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/the-anat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Cleese</td>\n",
       "      <td>Creativity in Management</td>\n",
       "      <td>You know, when Video Arts asked me if I'd like...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/creativi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>William Deresiewicz</td>\n",
       "      <td>Solitude and Leadership</td>\n",
       "      <td>My title must seem like a contradiction. What ...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/solitude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Richard Feynman</td>\n",
       "      <td>Seeking New Laws</td>\n",
       "      <td>What I want to talk to you about tonight is st...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/seeking-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neil Gaiman</td>\n",
       "      <td>Make Good Art</td>\n",
       "      <td>I never really expected to find myself giving ...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/make-goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>John W. Gardner</td>\n",
       "      <td>Personal Renewal</td>\n",
       "      <td>I'm going to talk about “Self-Renewal.” One of...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elizabeth Gilbert</td>\n",
       "      <td>Your Elusive Creative Genius</td>\n",
       "      <td>I am a writer. Writing books is my profession ...</td>\n",
       "      <td>https://jamesclear.com/great-speeches/your-elu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Orator                                Title  \\\n",
       "0  Chimamanda Ngozi Adichie         The Danger of a Single Story   \n",
       "1                Jeff Bezos  What Matters More Than Your Talents   \n",
       "2             John C. Bogle                               Enough   \n",
       "3               Brené Brown                 The Anatomy of Trust   \n",
       "4               John Cleese             Creativity in Management   \n",
       "5       William Deresiewicz              Solitude and Leadership   \n",
       "6           Richard Feynman                     Seeking New Laws   \n",
       "7               Neil Gaiman                        Make Good Art   \n",
       "8           John W. Gardner                     Personal Renewal   \n",
       "9         Elizabeth Gilbert         Your Elusive Creative Genius   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  I'm a storyteller. And I would like to tell yo...   \n",
       "1  As a kid, I spent my summers with my grandpare...   \n",
       "2  Here’s how I recall the wonderful story that s...   \n",
       "3  Oh, it just feels like an incredible understat...   \n",
       "4  You know, when Video Arts asked me if I'd like...   \n",
       "5  My title must seem like a contradiction. What ...   \n",
       "6  What I want to talk to you about tonight is st...   \n",
       "7  I never really expected to find myself giving ...   \n",
       "8  I'm going to talk about “Self-Renewal.” One of...   \n",
       "9  I am a writer. Writing books is my profession ...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://jamesclear.com/great-speeches/the-dang...  \n",
       "1  https://jamesclear.com/great-speeches/what-mat...  \n",
       "2  https://jamesclear.com/great-speeches/enough-b...  \n",
       "3  https://jamesclear.com/great-speeches/the-anat...  \n",
       "4  https://jamesclear.com/great-speeches/creativi...  \n",
       "5  https://jamesclear.com/great-speeches/solitude...  \n",
       "6  https://jamesclear.com/great-speeches/seeking-...  \n",
       "7  https://jamesclear.com/great-speeches/make-goo...  \n",
       "8  https://jamesclear.com/great-speeches/personal...  \n",
       "9  https://jamesclear.com/great-speeches/your-elu...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_speech_data(speech_urls,save_as='',n=5):\n",
    "    i=0\n",
    "    df = pd.DataFrame(columns=['Orator','Title','Transcript','Link'])\n",
    "    num_speeches = min(len(speech_urls),n)\n",
    "    driver = webdriver.Chrome(PATH+r'\\chromedriver.exe')\n",
    "    while i < num_speeches:\n",
    "        try:\n",
    "            driver.get(speech_urls[i])\n",
    "            transcript = ''\n",
    "            title_orator = driver.find_element_by_xpath(\"//h1[@class='entry-title']\").text\n",
    "            # Not the non-standard quotation marks in my regex string\n",
    "            title_orator_re = re.search(r'“(.+)”.+by (.+)', ' '.join(title_orator.split(\"\\n\")))\n",
    "            transcript_elements = driver.find_elements_by_xpath('//h2[text() = \"Speech Transcript\"]/following-sibling::p')\n",
    "            if not transcript_elements:\n",
    "                transcript_elements = driver.find_elements_by_xpath(\"//h2[contains(text(),'Speech Transcript')]/following-sibling::div/div/div/p\")\n",
    "            for p in transcript_elements:\n",
    "                transcript += p.text + ' '\n",
    "            df.loc[i] = [title_orator_re.group(2),title_orator_re.group(1),transcript,speech_urls[i]]\n",
    "        except:\n",
    "            print(i)\n",
    "            print(\"Unexpected error:\",sys.exc_info()[0],sys.exc_info()[1])\n",
    "        i+=1\n",
    "    driver.quit()\n",
    "    if save_as:\n",
    "        df.to_excel(save_as, index=False)\n",
    "    return df\n",
    "\n",
    "# replace the empty string with a file name to save\n",
    "scrape_speech_data(links,'',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I got the function working, my problem was getting the transcript for John C. Bogle's speech \"Enough\". Now I saw (since Selenium actually opens a window) that there's a banner that often came up for this page, but it's not actually a modal so I don't think that should be a problem. First I will take a look at the html. \n",
    "\n",
    "The html indeed has a different structure, but at least in the first 10 transcripts, it is the only page structured like that. After looking at the page for \"Enough\", I came added the next two lines:\n",
    "\n",
    "```if not transcript_elements:\n",
    "    transcript_elements = driver.find_elements_by_xpath(\"//h2[contains(text(),'Speech Transcript')]/following-sibling::div/div/div/p\")\n",
    "```\n",
    "\n",
    "Which uses this alternate x_path in the case that the usual ```transcript_elements``` list is empty. Although sort of hacky, it works and without giving me an error. We now have our complete speech dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code, make sure you insalled the necessary packages:\n",
    "\n",
    "`pip install beautifulsoup4`\n",
    "\n",
    "`pip install requests` (for http requests)\n",
    "\n",
    "`pip install lxml` (for parsing)\n",
    "\n",
    "If you have the time, I would recommend trying out both of these popular options because they are quite different and scraping $\\textit{can}$ be fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using bs4 for scraping lyrics from https://www.azlyrics.com/ which seems to have songs and albums besides \"Greatest Hits\" albums which we'll be avoiding. Using a Business Insider article from 2016, we'll collect lyrics from songs from the best selling albums of all time. \n",
    "\n",
    "Best selling is a quantifiable selection criteria, so I'll go with this methodology for songs. I'm selecting albums instead of individual songs because song popularity is very subjective (hard to find an objective list) and albums will have corpora that are more comparable to speeches than songs. Plus songs normally focus on one topic whereas speeches often have stories or subtopics that give them more variety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we want to check if the pages we are scraping allow it. https://www.businessinsider.com/robots.txt tells us, that for `User-agent: *` (ie. all bots), we cannot scrape a whole bunch of extensions. They don't disallow '/' so since my artice below is just \"businessinsider.com/...\" then I'm ok to scrape it.\n",
    "\n",
    "For how to interpret a robots.txt file, go to the [Google Webmasters](https://support.google.com/webmasters/answer/6062596?hl=en) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from time import sleep\n",
    "\n",
    "agent = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'}\n",
    "best_albums_src = requests.get('https://www.businessinsider.com/50-best-selling-albums-all-time-2016-9',headers=agent).text\n",
    "# class 'slide'\n",
    "soup = BeautifulSoup(best_albums_src, 'lxml')\n",
    "\n",
    "# show (still not that) pretty html\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slides = soup.find('div',class_='slide-wrapper')\n",
    "slide_ls = slides.find_all('div',class_='slide')\n",
    "len(slide_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so looks like we have out 50 best-selling albums. Next, we'll want the 5 best selling albums and artists without \"Greatest\" in the album title (since azlyrics doesn't have those albums and it's a good site to scrape). Possible alternatives like Lyrics.com are harder to navigate en masse (page urls can't be guessed since they have long numbers) and they don't have straightforward album-song navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Michael Jackson', '\"Thriller\"'],\n",
       " ['Eagles', '\"Hotel California\"'],\n",
       " ['Led Zeppelin', '\"Led Zeppelin IV\"'],\n",
       " ['Pink Floyd', '\"The Wall\"'],\n",
       " ['AC/DC', '\"Back In Black\"'],\n",
       " ['Garth Brooks', '\"Double Live\"'],\n",
       " ['Hootie & The Blowfish', '\"Cracked Rear View\"'],\n",
       " ['Fleetwood Mac', '\"Rumours\"'],\n",
       " ['Shania Twain', '\"Come On Over\"'],\n",
       " ['The Beatles', '\"The Beatles\" (\"The White Album\"']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_albums = 10\n",
    "\n",
    "def get_valid_albums(slides, n):\n",
    "    i=len(slides)-1\n",
    "    selected_albums = 0\n",
    "    album_info = []\n",
    "    while i > -1 and selected_albums < n:\n",
    "        txt = slides[i].text\n",
    "        if \"Greatest\" not in txt:\n",
    "            artist_album_str = re.search(r'.*\\d\\. (.+) — (\".+\").*', txt)\n",
    "            album_info.append([artist_album_str.group(1),artist_album_str.group(2)])\n",
    "            selected_albums+=1\n",
    "        i-=1\n",
    "    return album_info\n",
    "\n",
    "# Note that album names are in quotes on AZlyrics so we'll keep them in the string\n",
    "art_alb_pairs = get_valid_albums(slide_ls, num_albums)\n",
    "art_alb_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at azlyrics, the album name doesn't have quotes in the same spots\n",
    "#   (Also I didn't account for parentheses)\n",
    "art_alb_pairs[-1] =  ['The Beatles', '\"The Beatles (The White Album)\"']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have our artist and albums. The URL with album and song lyrics is pretty straightforward. URLs follow the pattern\n",
    "`https://www.azlyrics.com/<first letter of artist's last name>/<last name>.html` or \n",
    "`https://www.azlyrics.com/<first letter of group name>/<group name (only letters)>.html`\n",
    "\n",
    "Our problem is that we can't really tell if the name is a group or an individual (and I'm not about to train a model to distinguish the two). I'll be using the fact that names are (usually) two words and that we would be redirected to the main page if the url isn't found to bypass this problem. Artists with three names (so far as I've seen) have URLs like groups. There's also some inconsistency with the two word names since Billy Joel is at `/b/billyjoel.html` and Michael Jackson is at `/j/jackson.html`. I thought maybe since the Jackson 5 was linked on the same page that this was the reason for a different pattern, but David bowie is also at `/b/bowie.html`. I won't agonize it too much, I will just see if I can get success on one of the possible pages.\n",
    "\n",
    "The home page has \"Welcome to AZLyrics!\" so I'll be looking for that as a sign that my URL didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Welcome to AZLyrics!</h1>\n",
      "https://www.azlyrics.com/h/hootie.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/hannahjane.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/holdmyhand.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/lethercry.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/onlywannabewithyou.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/runningfromanangel.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/imgoinghome.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/drowning.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/time.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/lookaway.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/noteventhetrees.html',\n",
       "  'https://www.azlyrics.com/h/hootie.html/../../lyrics/hootietheblowfish/goodbye.html'],\n",
       " 'https://www.azlyrics.com/h/hootie.html')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az_root = 'https://www.azlyrics.com'\n",
    "\n",
    "def get_songs(artist,album, root_url=az_root):\n",
    "    h1 = None\n",
    "    songs=[]\n",
    "    artist_lc = artist.lower()\n",
    "    name = artist_lc.split()\n",
    "    artist_letters = re.sub('[^a-zA-Z]+', '', artist_lc)\n",
    "    # try last name centric URL\n",
    "    # ex. Michael Jackson -> /j/jackson.html\n",
    "    if len(name) == 2:\n",
    "        artist_url = '/'.join([root_url,name[1][0],name[1]])+'.html'\n",
    "        artist_url = artist_url.lower()\n",
    "        src = requests.get(artist_url,headers=agent).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        h1 = soup.find('h1')\n",
    "    # try full artist name url\n",
    "    # ex. AC/DC -> /a/acdc.html\n",
    "    if h1 is None or h1 is not None and h1.text == \"Welcome to AZLyrics!\":\n",
    "        artist_url = '/'.join([root_url,artist[0],artist_letters])+'.html'\n",
    "        artist_url = artist_url.lower()\n",
    "        src = requests.get(artist_url,headers=agent).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        h1 = soup.find('h1')\n",
    "    # try first word centric URL\n",
    "    # ex. Fleetwood Mac -> /f/fleetwood.html\n",
    "    if h1 is None or h1 is not None and h1.text == \"Welcome to AZLyrics!\":\n",
    "        artist_url = '/'.join([root_url,name[0][0],name[0]])+'.html'\n",
    "        artist_url = artist_url.lower()\n",
    "        src = requests.get(artist_url,headers=agent).text\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "#     print(artist_url)\n",
    "    try:\n",
    "        # every other sibling is a navigablestring (and don't want to add more complexity to the loop)\n",
    "        cur_node = soup.findAll('b',string=album)[0].parent.next_sibling.next_sibling\n",
    "        while \"listalbum-item\" in  cur_node['class']:\n",
    "            songs.append(artist_url + '/../' + cur_node.find('a')['href'])\n",
    "            cur_node = cur_node.next_sibling.next_sibling\n",
    "    except:\n",
    "        print(sys.exc_info()[0],sys.exc_info()[1])\n",
    "    return songs, artist_url\n",
    "\n",
    "i=6\n",
    "get_songs(art_alb_pairs[i][0],art_alb_pairs[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Well... maybe we're halfway there, but that's still something!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>\"Thriller\"</td>\n",
       "      <td>\\n\\r\\nI said you wanna be startin' somethin'\\n...</td>\n",
       "      <td>https://www.azlyrics.com/j/jackson.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>\"Hotel California\"</td>\n",
       "      <td>\\n\\r\\nOn a dark desert highway, cool wind in m...</td>\n",
       "      <td>https://www.azlyrics.com/e/eagles.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Led Zeppelin</td>\n",
       "      <td>\"Led Zeppelin IV\"</td>\n",
       "      <td>\\n\\r\\nHey, hey mama, said the way you move\\nGo...</td>\n",
       "      <td>https://www.azlyrics.com/l/ledzeppelin.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pink Floyd</td>\n",
       "      <td>\"The Wall\"</td>\n",
       "      <td>\\n\\r\\n(We came in)\\n\\nSo ya thought ya might l...</td>\n",
       "      <td>https://www.azlyrics.com/p/pinkfloyd.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC/DC</td>\n",
       "      <td>\"Back In Black\"</td>\n",
       "      <td>\\n\\r\\nI'm rolling thunder pouring rain\\nI'm co...</td>\n",
       "      <td>https://www.azlyrics.com/a/acdc.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Garth Brooks</td>\n",
       "      <td>\"Double Live\"</td>\n",
       "      <td>\\n\\r\\nWe all came here for a party tonight\\nAn...</td>\n",
       "      <td>https://www.azlyrics.com/b/brooks.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hootie &amp; The Blowfish</td>\n",
       "      <td>\"Cracked Rear View\"</td>\n",
       "      <td>\\n\\r\\nYou got your big girl \\nNow you've got y...</td>\n",
       "      <td>https://www.azlyrics.com/h/hootie.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fleetwood Mac</td>\n",
       "      <td>\"Rumours\"</td>\n",
       "      <td>\\n\\r\\nI know there's nothing to say\\nSomeone h...</td>\n",
       "      <td>https://www.azlyrics.com/f/fleetwood.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shania Twain</td>\n",
       "      <td>\"Come On Over\"</td>\n",
       "      <td>\\n\\r\\nLet's go girls! Come on.\\n\\nI'm going ou...</td>\n",
       "      <td>https://www.azlyrics.com/t/twain.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Beatles</td>\n",
       "      <td>\"The Beatles (The White Album)\"</td>\n",
       "      <td>\\n\\r\\nOh, flew in by Miami Beach B.O.A.C.\\nDid...</td>\n",
       "      <td>https://www.azlyrics.com/b/beatles.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Artist                            Album  \\\n",
       "0        Michael Jackson                       \"Thriller\"   \n",
       "1                 Eagles               \"Hotel California\"   \n",
       "2           Led Zeppelin                \"Led Zeppelin IV\"   \n",
       "3             Pink Floyd                       \"The Wall\"   \n",
       "4                  AC/DC                  \"Back In Black\"   \n",
       "5           Garth Brooks                    \"Double Live\"   \n",
       "6  Hootie & The Blowfish              \"Cracked Rear View\"   \n",
       "7          Fleetwood Mac                        \"Rumours\"   \n",
       "8           Shania Twain                   \"Come On Over\"   \n",
       "9            The Beatles  \"The Beatles (The White Album)\"   \n",
       "\n",
       "                                               Lyric  \\\n",
       "0  \\n\\r\\nI said you wanna be startin' somethin'\\n...   \n",
       "1  \\n\\r\\nOn a dark desert highway, cool wind in m...   \n",
       "2  \\n\\r\\nHey, hey mama, said the way you move\\nGo...   \n",
       "3  \\n\\r\\n(We came in)\\n\\nSo ya thought ya might l...   \n",
       "4  \\n\\r\\nI'm rolling thunder pouring rain\\nI'm co...   \n",
       "5  \\n\\r\\nWe all came here for a party tonight\\nAn...   \n",
       "6  \\n\\r\\nYou got your big girl \\nNow you've got y...   \n",
       "7  \\n\\r\\nI know there's nothing to say\\nSomeone h...   \n",
       "8  \\n\\r\\nLet's go girls! Come on.\\n\\nI'm going ou...   \n",
       "9  \\n\\r\\nOh, flew in by Miami Beach B.O.A.C.\\nDid...   \n",
       "\n",
       "                                   Artist_Link  \n",
       "0      https://www.azlyrics.com/j/jackson.html  \n",
       "1       https://www.azlyrics.com/e/eagles.html  \n",
       "2  https://www.azlyrics.com/l/ledzeppelin.html  \n",
       "3    https://www.azlyrics.com/p/pinkfloyd.html  \n",
       "4         https://www.azlyrics.com/a/acdc.html  \n",
       "5       https://www.azlyrics.com/b/brooks.html  \n",
       "6       https://www.azlyrics.com/h/hootie.html  \n",
       "7    https://www.azlyrics.com/f/fleetwood.html  \n",
       "8        https://www.azlyrics.com/t/twain.html  \n",
       "9      https://www.azlyrics.com/b/beatles.html  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_speech_data(aa_list,save_as='',n=10):\n",
    "    i=0\n",
    "    df = pd.DataFrame(columns=['Artist','Album','Lyric','Artist_Link'])\n",
    "    num_albums = min(len(aa_list),n)\n",
    "    for aa in aa_list:\n",
    "        try:\n",
    "            song_links,artist_url = get_songs(aa[0],aa[1])\n",
    "            lyrics = ''\n",
    "            for song in song_links:\n",
    "                song_src = requests.get(song,headers=agent).text\n",
    "                soup = BeautifulSoup(song_src, 'lxml')\n",
    "                node = soup.find('div',class_='ringtone').next_sibling\n",
    "                while True:\n",
    "                    if type(node) is not NavigableString and node.name == 'div' and not node.attrs.get(\"class\"):\n",
    "                        lyrics += node.text + ' '\n",
    "                        break\n",
    "                    node = node.next_sibling\n",
    "                # Suspend the thread - don't hit the site too fast\n",
    "                sleep(15)\n",
    "        except:\n",
    "            print(\"Unexpected error:\",sys.exc_info()[0],sys.exc_info()[1])\n",
    "        df.loc[i] = [aa[0],aa[1],lyrics,artist_url]\n",
    "        i+=1\n",
    "    if save_as:\n",
    "        df.to_excel(save_as, index=False)\n",
    "    return df\n",
    "\n",
    "# scraping takes a while (especially when using the function sleep, which you should be using)\n",
    "# scrape_speech_data(art_alb_pairs,'songs_raw.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
